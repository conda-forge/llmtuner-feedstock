{% set name = "llmtuner" %}
{% set version = "0.9.4" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/hiyouga/LLaMA-Factory/archive/v{{ version }}.tar.gz
  sha256: 2ce772945da1c7c28964e23d8bae429222749a4e9df47191e2159e3f72f638fd

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python {{ python_min }}
    - hatchling
    - pip
  run:
    - hf-transfer
    - modelscope
    - safetensors
    - torchaudio >=2.4.0
    - torchdata >=0.10.0,<=0.11.0
    - torchvision >=0.19.0
    - omegaconf
    - librosa
    - tokenizers >=0.19.0,<=0.21.1
    - av
    - numpy
    - pandas
    - tyro <0.9.0
    - pyyaml
    - packaging
    - python >={{ python_min }}
    - pytorch >=2.4.0
    - transformers >=4.51.0,<=4.57.1,!=4.52.0,!=4.57.0
    - datasets >=2.16.0,<=4.0.0
    - accelerate >=1.3.0,<=1.11.0
    - peft >=0.14.0,<=0.17.1
    - trl >=0.18.0,<=0.24.0
    - gradio >=4.38.0,<=5.50.0
    - scipy
    - einops
    - sentencepiece
    - protobuf
    - uvicorn
    - pydantic
    - fastapi
    - sse-starlette
    - matplotlib-base >=3.7.0
    - fire
    - galore-torch
    - tiktoken
    - eval-type-backport

test:
  imports:
    - llamafactory
  commands:
    - pip check
  requires:
    - pip
    - python {{ python_min }}

about:
  home: https://github.com/hiyouga/LLaMA-Factory
  summary: Easy-to-use LLM fine-tuning framework
  license: Apache-2.0
  license_file: LICENSE

extra:
  recipe-maintainers:
    - shaowei-su
    - jan-janssen
