{% set name = "llmtuner" %}
{% set version = "0.9.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/hiyouga/LLaMA-Factory/archive/v{{ version }}.tar.gz
  sha256: c43afed4764be02c1bc661d706293f430e072200b9a297f493c34a41e044dfc0

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 1

requirements:
  host:
    - python {{ python_min }}
    - setuptools >=61.0
    - pip
  run:
    - av
    - numpy <2.0.0
    - pandas >=2.0.0
    - tyro <0.9.0
    - pyyaml
    - packaging
    - python >={{ python_min }}
    - pytorch >=1.13.1
    - transformers >=4.41.2,<=4.46.1
    - datasets >=2.16.0,<=3.1.0
    - accelerate >=0.34.0,<=1.0.1
    - peft >=0.11.1,<=0.12.0
    - trl >=0.8.6,<=0.9.6
    - gradio >=4.0.0,<5.0.0
    - scipy
    - einops
    - sentencepiece
    - protobuf
    - uvicorn
    - pydantic
    - fastapi
    - sse-starlette
    - matplotlib-base >=3.7.0
    - fire
    - galore-torch
    - tiktoken
    - eval-type-backport

test:
  imports:
    - llamafactory
  commands:
    - pip check
  requires:
    - pip
    - python {{ python_min }}

about:
  home: https://github.com/hiyouga/LLaMA-Factory
  summary: Easy-to-use LLM fine-tuning framework
  license: Apache-2.0
  license_file: LICENSE

extra:
  recipe-maintainers:
    - jan-janssen
